{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mg11nPfLGjFP"
      },
      "source": [
        "# Project 2\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "oPNXL4wgGmij"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "%config InlineBackend.figure_format = 'retina'  #To get figures with high quality!\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch import optim\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import torchvision"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6d0MOJvfGcGH"
      },
      "source": [
        "## Loading the dataset CIFAR10\n",
        "\n",
        "We are told to classify birds from cats in the CIFAR10 dataset. This means that we will only use the images that are labeled as birds or cats. In the CIFAR10 these labels are 2 and 3 respectively. We will have the training, validation and test datasets."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X5BD6thUGbuw",
        "outputId": "77389e95-b623-4552-dc44-9b386a7dbe15"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        }
      ],
      "source": [
        "from torchvision import datasets, transforms\n",
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor(),\n",
        "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "\n",
        "trainset = datasets.CIFAR10(root='./data', train=True,\n",
        "                                        download=True, transform=transform)\n",
        "\n",
        "#Filtering the birds and cats images from the train set\n",
        "trainset.targets = torch.tensor(trainset.targets)\n",
        "mask = (trainset.targets == 2) | (trainset.targets == 3)\n",
        "trainset.targets = (trainset.targets[mask] - 2)  # Adjust labels to be 0 for the birds and 1 cats\n",
        "trainset.data = trainset.data[mask.numpy().astype(bool)]\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64,\n",
        "                                          shuffle=True, num_workers=2)\n",
        "\n",
        "\n",
        "testset = datasets.CIFAR10(root='./data', train=False,\n",
        "                                       download=True, transform=transform)\n",
        "\n",
        "#Filtering the birds and cats images from the test set\n",
        "testset.targets = torch.tensor(testset.targets)\n",
        "mask = (testset.targets == 2) | (testset.targets == 3)\n",
        "testset.targets = (testset.targets[mask] - 2)  # Adjust labels to be 0 for the birds and 1 cats\n",
        "testset.data = testset.data[mask.numpy().astype(bool)]\n",
        "\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=64,\n",
        "                                         shuffle=False, num_workers=2)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Lm3CuWIPU8m"
      },
      "source": [
        "Splitting the training into train and valid (80/20)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "box8WugMOv6o",
        "outputId": "d6269948-4e5b-4dac-df46-e1ce0603095c"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4P2QWPiRHt-E"
      },
      "source": [
        "## Implementation of a Lenet5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "b0zIFluwC5_J"
      },
      "outputs": [],
      "source": [
        "class Lenet5(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        self.conv_part = nn.Sequential( # As images are rgb we have 3 input channels\n",
        "            nn.Conv2d(in_channels=3, out_channels=6,\n",
        "                      kernel_size=5, stride=1, padding=0),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "            nn.Conv2d(6, 16, kernel_size=5),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        )\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(16 * 5 * 5, 120), # The input dimension at the classifier is 16 images of 5x5 so 16*5*5\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(120, 84),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(84, 2), # As we are just classifying two classes the output must be 2\n",
        "            nn.LogSigmoid()\n",
        "\n",
        "        )\n",
        "        self.lr = 0.001 #Learning Rate\n",
        "\n",
        "        self.optim = optim.Adam(self.parameters(), self.lr)\n",
        "\n",
        "        self.criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "        self.loss_during_training = []\n",
        "\n",
        "        self.valid_loss_during_training = []\n",
        "\n",
        "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "        \n",
        "        if torch.cuda.is_available():\n",
        "                print(\"Switching to GPU\")\n",
        "        else:\n",
        "                print(\"GPU not available, running CPU\")\n",
        "        \n",
        "        self.to(self.device)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv_part(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = self.classifier(x)\n",
        "        return x\n",
        "\n",
        "    def trainloop(self,trainloader,validloader,epochs):\n",
        "\n",
        "        self.train()\n",
        "        for e in range(epochs):\n",
        "\n",
        "            start_time = time.time()\n",
        "\n",
        "            running_loss = 0.\n",
        "\n",
        "            for images, labels in trainloader:\n",
        "\n",
        "                # Move input and label tensors to the default device\n",
        "                images, labels = images.to(self.device), labels.to(self.device)  \n",
        "        \n",
        "                self.optim.zero_grad()\n",
        "\n",
        "                out = self.forward(images)\n",
        "\n",
        "\n",
        "                loss = self.criterion(out,labels)\n",
        "\n",
        "                running_loss += loss.item()\n",
        "\n",
        "\n",
        "                loss.backward()\n",
        "                self.optim.step()\n",
        "\n",
        "            self.loss_during_training.append(running_loss/len(trainloader))\n",
        "\n",
        "            with torch.no_grad():\n",
        "\n",
        "                  self.eval()\n",
        "\n",
        "                  running_loss = 0.\n",
        "\n",
        "                  for images,labels in validloader:\n",
        "\n",
        "                      # Move input and label tensors to the default device\n",
        "                      images, labels = images.to(self.device), labels.to(self.device)  \n",
        "        \n",
        "                      out = self.forward(images)\n",
        "\n",
        "                      #Loss function\n",
        "                      loss = self.criterion(out,labels)\n",
        "\n",
        "                      running_loss += loss.item()\n",
        "\n",
        "                  self.valid_loss_during_training.append(running_loss/len(validloader))\n",
        "\n",
        "                  self.train()\n",
        "\n",
        "\n",
        "            print(\"Epoch %d. Training loss: %f, Validation loss: %f, Time per epoch: %f seconds\" \n",
        "                      %(e,self.loss_during_training[-1],self.valid_loss_during_training[-1],\n",
        "                       (time.time() - start_time)))\n",
        "    \n",
        "    def compute_accuracy(self, dataloader):\n",
        "      correct = 0\n",
        "      total = 0\n",
        "      with torch.no_grad():\n",
        "        self.eval()\n",
        "        for images, labels in dataloader:\n",
        "                # Move input and label tensors to the default device\n",
        "                images, labels = images.to(self.device), labels.to(self.device)  \n",
        "        \n",
        "                outputs = self(images)\n",
        "\n",
        "                _, predicted = torch.max(outputs.data, 1)\n",
        "                total += labels.size(0)\n",
        "                correct += (predicted == labels).sum().item()\n",
        "        accuracy = correct / total\n",
        "      return accuracy\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V99QnKRmECcy",
        "outputId": "e94ad318-9855-4f40-ab5c-ef1a6fd280af"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Switching to GPU\n",
            "Epoch 0. Training loss: 0.585952, Validation loss: 0.537629, Time per epoch: 3.761291 seconds\n",
            "Epoch 1. Training loss: 0.511744, Validation loss: 0.516237, Time per epoch: 1.562532 seconds\n",
            "Epoch 2. Training loss: 0.475808, Validation loss: 0.490622, Time per epoch: 1.520499 seconds\n",
            "Epoch 3. Training loss: 0.459729, Validation loss: 0.472432, Time per epoch: 1.365472 seconds\n",
            "Epoch 4. Training loss: 0.431958, Validation loss: 0.449626, Time per epoch: 1.367150 seconds\n",
            "Epoch 5. Training loss: 0.414457, Validation loss: 0.441921, Time per epoch: 1.451922 seconds\n",
            "Epoch 6. Training loss: 0.408774, Validation loss: 0.440843, Time per epoch: 1.381368 seconds\n",
            "Epoch 7. Training loss: 0.398327, Validation loss: 0.440901, Time per epoch: 1.387728 seconds\n",
            "Epoch 8. Training loss: 0.377847, Validation loss: 0.411737, Time per epoch: 1.415927 seconds\n",
            "Epoch 9. Training loss: 0.361752, Validation loss: 0.416151, Time per epoch: 1.345981 seconds\n",
            "Epoch 10. Training loss: 0.349519, Validation loss: 0.406718, Time per epoch: 1.438508 seconds\n",
            "Epoch 11. Training loss: 0.343235, Validation loss: 0.418321, Time per epoch: 1.439226 seconds\n",
            "Epoch 12. Training loss: 0.322796, Validation loss: 0.420376, Time per epoch: 1.429047 seconds\n",
            "Epoch 13. Training loss: 0.305741, Validation loss: 0.417771, Time per epoch: 2.021789 seconds\n",
            "Epoch 14. Training loss: 0.289612, Validation loss: 0.437721, Time per epoch: 2.018114 seconds\n",
            "Epoch 15. Training loss: 0.273829, Validation loss: 0.439783, Time per epoch: 1.916480 seconds\n",
            "Epoch 16. Training loss: 0.253863, Validation loss: 0.473501, Time per epoch: 1.831976 seconds\n",
            "Epoch 17. Training loss: 0.232310, Validation loss: 0.493383, Time per epoch: 1.463243 seconds\n",
            "Epoch 18. Training loss: 0.213096, Validation loss: 0.504606, Time per epoch: 1.587338 seconds\n",
            "Epoch 19. Training loss: 0.183033, Validation loss: 0.615789, Time per epoch: 1.422487 seconds\n",
            "Epoch 20. Training loss: 0.190815, Validation loss: 0.547873, Time per epoch: 1.366830 seconds\n",
            "Epoch 21. Training loss: 0.148770, Validation loss: 0.656403, Time per epoch: 1.359476 seconds\n",
            "Epoch 22. Training loss: 0.130552, Validation loss: 0.640794, Time per epoch: 1.354558 seconds\n",
            "Epoch 23. Training loss: 0.117979, Validation loss: 0.706368, Time per epoch: 1.332389 seconds\n",
            "Epoch 24. Training loss: 0.095959, Validation loss: 0.704916, Time per epoch: 1.343237 seconds\n",
            "Epoch 25. Training loss: 0.092084, Validation loss: 0.815919, Time per epoch: 1.366724 seconds\n",
            "Epoch 26. Training loss: 0.082194, Validation loss: 0.812337, Time per epoch: 1.464826 seconds\n",
            "Epoch 27. Training loss: 0.070792, Validation loss: 0.987131, Time per epoch: 1.330355 seconds\n",
            "Epoch 28. Training loss: 0.063664, Validation loss: 0.983412, Time per epoch: 1.348137 seconds\n",
            "Epoch 29. Training loss: 0.051850, Validation loss: 0.983358, Time per epoch: 1.359743 seconds\n"
          ]
        }
      ],
      "source": [
        "model = Lenet5()\n",
        "model.trainloop(trainloader,testloader,30)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Tiempo con CPU: \n",
        "# sobre 1.8 segundos\n",
        "# ACC is 0.79\n",
        "\n",
        "#Tiempo con CPU: \n",
        "# sobre 1.4 segundos\n",
        "# ACC is 0.8015, igual"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kzk1Lup_EzZW",
        "outputId": "57e6fd2d-d462-4792-bd06-39e8fc18edf8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.8015\n"
          ]
        }
      ],
      "source": [
        "print(model.compute_accuracy(testloader))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
