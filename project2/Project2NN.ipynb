{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Project 2\n"
      ],
      "metadata": {
        "id": "Mg11nPfLGjFP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%matplotlib inline\n",
        "%config InlineBackend.figure_format = 'retina'  #To get figures with high quality!\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch import optim\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import torchvision"
      ],
      "metadata": {
        "id": "oPNXL4wgGmij"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loading the dataset CIFAR10\n",
        "\n",
        "We are told to classify birds from cats in the CIFAR10 dataset. This means that we will only use the images that are labeled as birds or cats. In the CIFAR10 these labels are 2 and 3 respectively. We will have the training, validation and test datasets."
      ],
      "metadata": {
        "id": "6d0MOJvfGcGH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision import datasets, transforms\n",
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor(),\n",
        "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "\n",
        "trainset = datasets.CIFAR10(root='./data', train=True,\n",
        "                                        download=True, transform=transform)\n",
        "\n",
        "#Filtering the birds and cats images from the train set\n",
        "trainset.targets = torch.tensor(trainset.targets)\n",
        "mask = (trainset.targets == 2) | (trainset.targets == 3)\n",
        "trainset.targets = (trainset.targets[mask] - 2)  # Adjust labels to be 0 for the birds and 1 cats\n",
        "trainset.data = trainset.data[mask.numpy().astype(bool)]\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64,\n",
        "                                          shuffle=True, num_workers=2)\n",
        "\n",
        "\n",
        "testset = datasets.CIFAR10(root='./data', train=False,\n",
        "                                       download=True, transform=transform)\n",
        "\n",
        "#Filtering the birds and cats images from the test set\n",
        "testset.targets = torch.tensor(testset.targets)\n",
        "mask = (testset.targets == 2) | (testset.targets == 3)\n",
        "testset.targets = (testset.targets[mask] - 2)  # Adjust labels to be 0 for the birds and 1 cats\n",
        "testset.data = testset.data[mask.numpy().astype(bool)]\n",
        "\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=64,\n",
        "                                         shuffle=False, num_workers=2)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X5BD6thUGbuw",
        "outputId": "77389e95-b623-4552-dc44-9b386a7dbe15"
      },
      "execution_count": 153,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Splitting the training into train and valid (80/20)"
      ],
      "metadata": {
        "id": "8Lm3CuWIPU8m"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "box8WugMOv6o",
        "outputId": "d6269948-4e5b-4dac-df46-e1ce0603095c"
      },
      "execution_count": 151,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "100 25\n",
            "100 25\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Implementation of a Lenet5"
      ],
      "metadata": {
        "id": "4P2QWPiRHt-E"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 157,
      "metadata": {
        "id": "b0zIFluwC5_J"
      },
      "outputs": [],
      "source": [
        "class Lenet5(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        self.conv_part = nn.Sequential( # As images are rgb we have 3 input channels\n",
        "            nn.Conv2d(in_channels=3, out_channels=6,\n",
        "                      kernel_size=5, stride=1, padding=0),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "            nn.Conv2d(6, 16, kernel_size=5),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        )\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(16 * 5 * 5, 120), # The input dimension at the classifier is 16 images of 5x5 so 16*5*5\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(120, 84),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(84, 2), # As we are just classifying two classes the output must be 2\n",
        "            nn.LogSigmoid()\n",
        "\n",
        "        )\n",
        "        self.lr = 0.001 #Learning Rate\n",
        "\n",
        "        self.optim = optim.Adam(self.parameters(), self.lr)\n",
        "\n",
        "        self.criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "        self.loss_during_training = []\n",
        "\n",
        "        self.valid_loss_during_training = []\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv_part(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = self.classifier(x)\n",
        "        return x\n",
        "\n",
        "    def trainloop(self,trainloader,validloader,epochs):\n",
        "\n",
        "        self.train()\n",
        "        for e in range(epochs):\n",
        "\n",
        "            running_loss = 0.\n",
        "\n",
        "            for images, labels in trainloader:\n",
        "\n",
        "                self.optim.zero_grad()\n",
        "\n",
        "                out = self.forward(images)\n",
        "\n",
        "\n",
        "                loss = self.criterion(out,labels)\n",
        "\n",
        "                running_loss += loss.item()\n",
        "\n",
        "\n",
        "                loss.backward()\n",
        "                self.optim.step()\n",
        "\n",
        "            self.loss_during_training.append(running_loss/len(trainloader))\n",
        "\n",
        "            with torch.no_grad():\n",
        "\n",
        "                  self.eval()\n",
        "\n",
        "                  running_loss = 0.\n",
        "\n",
        "                  for images,labels in validloader:\n",
        "\n",
        "\n",
        "                      out = self.forward(images)\n",
        "\n",
        "                      #Loss function\n",
        "                      loss = self.criterion(out,labels)\n",
        "\n",
        "                      running_loss += loss.item()\n",
        "\n",
        "                  self.valid_loss_during_training.append(running_loss/len(validloader))\n",
        "\n",
        "                  self.train()\n",
        "\n",
        "\n",
        "            print(\"Epoch\", e  ,\". Training loss: \",self.loss_during_training[-1],\" Valid loss: \",self.valid_loss_during_training[-1])\n",
        "\n",
        "    def compute_accuracy(self, dataloader):\n",
        "      correct = 0\n",
        "      total = 0\n",
        "      with torch.no_grad():\n",
        "        self.eval()\n",
        "        for data in dataloader:\n",
        "                images, labels = data\n",
        "                outputs = self(images)\n",
        "\n",
        "                _, predicted = torch.max(outputs.data, 1)\n",
        "                total += labels.size(0)\n",
        "                correct += (predicted == labels).sum().item()\n",
        "        accuracy = correct / total\n",
        "      return accuracy\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = Lenet5()\n",
        "model.trainloop(trainloader,testloader,30)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V99QnKRmECcy",
        "outputId": "e94ad318-9855-4f40-ab5c-ef1a6fd280af"
      },
      "execution_count": 158,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0 . Training loss:  0.5934792548228222  Valid loss:  0.5239438144490123\n",
            "Epoch 1 . Training loss:  0.48836401655415823  Valid loss:  0.4764425475150347\n",
            "Epoch 2 . Training loss:  0.45911102120284064  Valid loss:  0.4716479741036892\n",
            "Epoch 3 . Training loss:  0.43069018708292844  Valid loss:  0.46636530943214893\n",
            "Epoch 4 . Training loss:  0.41172183556541514  Valid loss:  0.4406569553539157\n",
            "Epoch 5 . Training loss:  0.39494435489177704  Valid loss:  0.44568847957998514\n",
            "Epoch 6 . Training loss:  0.37349235612875337  Valid loss:  0.4377274885773659\n",
            "Epoch 7 . Training loss:  0.3515718026905303  Valid loss:  0.4339816989377141\n",
            "Epoch 8 . Training loss:  0.33702642845500047  Valid loss:  0.45053990837186575\n",
            "Epoch 9 . Training loss:  0.31685814128559864  Valid loss:  0.4725383296608925\n",
            "Epoch 10 . Training loss:  0.3024973916779658  Valid loss:  0.44063428696244955\n",
            "Epoch 11 . Training loss:  0.2824957162901095  Valid loss:  0.48118692077696323\n",
            "Epoch 12 . Training loss:  0.2615491388140211  Valid loss:  0.4617502298206091\n",
            "Epoch 13 . Training loss:  0.2402546675341904  Valid loss:  0.5221519637852907\n",
            "Epoch 14 . Training loss:  0.21202505128398821  Valid loss:  0.5287998672574759\n",
            "Epoch 15 . Training loss:  0.19853158394812018  Valid loss:  0.5429307501763105\n",
            "Epoch 16 . Training loss:  0.16871358133899939  Valid loss:  0.6181804658845067\n",
            "Epoch 17 . Training loss:  0.15085535985269363  Valid loss:  0.6871739085763693\n",
            "Epoch 18 . Training loss:  0.13982473133475917  Valid loss:  0.6716974908486009\n",
            "Epoch 19 . Training loss:  0.11412819060882565  Valid loss:  0.8173041446134448\n",
            "Epoch 20 . Training loss:  0.10615245681137415  Valid loss:  0.821396853774786\n",
            "Epoch 21 . Training loss:  0.09013883954590293  Valid loss:  0.8775041829794645\n",
            "Epoch 22 . Training loss:  0.07200324802606065  Valid loss:  0.9940467067062855\n",
            "Epoch 23 . Training loss:  0.09589921984047434  Valid loss:  1.00528275500983\n",
            "Epoch 24 . Training loss:  0.055501746405271966  Valid loss:  1.1303396690636873\n",
            "Epoch 25 . Training loss:  0.03715734859590365  Valid loss:  1.194596741348505\n",
            "Epoch 26 . Training loss:  0.04617889634197115  Valid loss:  1.2710060086101294\n",
            "Epoch 27 . Training loss:  0.06013048090452957  Valid loss:  1.0846889670938253\n",
            "Epoch 28 . Training loss:  0.03898103299675284  Valid loss:  1.3065795078873634\n",
            "Epoch 29 . Training loss:  0.029740980374745454  Valid loss:  1.335709972307086\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(model.compute_accuracy(testloader))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kzk1Lup_EzZW",
        "outputId": "57e6fd2d-d462-4792-bd06-39e8fc18edf8"
      },
      "execution_count": 159,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.793\n"
          ]
        }
      ]
    }
  ]
}